---
import Layout from '../../layouts/Layout.astro';
const base = import.meta.env.BASE_URL;
---

<Layout title="Tetris DQN -- Reward Shaping Experiments" description="Scientific analysis of reward shaping for Tetris DQN: why sparse rewards fail, how each penalty component contributes, and experimental results showing a 100x improvement.">
  <div style="max-width: 1100px; margin: 0 auto; padding: 3rem 1.5rem;">

    <div style="margin-bottom: 2.5rem;">
      <div style="display: flex; gap: 0.5rem; flex-wrap: wrap; margin-bottom: 0.8rem;">
        <a href={`${base}tetris/`} style="color: var(--text-secondary); text-decoration: none; font-size: 0.9rem;">Tetris DQN</a>
        <span style="color: var(--text-secondary);">/</span>
        <span style="color: var(--text-primary); font-size: 0.9rem;">Reward Shaping</span>
      </div>
      <div style="display: flex; gap: 0.5rem; flex-wrap: wrap; margin-bottom: 1rem;">
        <span class="tag tag-orange">Reward Shaping</span>
        <span class="tag tag-blue">Credit Assignment</span>
        <span class="tag tag-green">Experiments</span>
      </div>
      <h1 class="gradient-text" style="font-size: 2.6rem; font-weight: 800; margin-bottom: 1rem;">
        Reward Shaping Experiments
      </h1>
      <p style="color: var(--text-secondary); font-size: 1.15rem; max-width: 750px; line-height: 1.7;">
        Why sparse rewards fail for Tetris, how each penalty component changes the optimization
        landscape, and experimental evidence of a 100x improvement through reward engineering.
      </p>
    </div>

    <!-- Key results -->
    <div style="display: grid; grid-template-columns: repeat(auto-fill, minmax(200px, 1fr)); gap: 1rem; margin-bottom: 2.5rem;">
      <div class="stat-card" style="text-align: center; border-top: 3px solid var(--accent-orange);">
        <div style="font-size: 2rem; font-weight: 800; color: var(--text-secondary);">216</div>
        <div style="color: var(--text-secondary); font-size: 0.85rem; margin-top: 0.3rem;">Lines (sparse reward)</div>
      </div>
      <div style="display: flex; align-items: center; justify-content: center; font-size: 2rem; color: var(--text-secondary);">-></div>
      <div class="stat-card" style="text-align: center; border-top: 3px solid var(--accent-green);">
        <div style="font-size: 2rem; font-weight: 800; color: var(--accent-green);">22,645</div>
        <div style="color: var(--text-secondary); font-size: 0.85rem; margin-top: 0.3rem;">Lines (shaped reward)</div>
      </div>
      <div class="stat-card" style="text-align: center; border-top: 3px solid var(--accent-blue);">
        <div style="font-size: 2rem; font-weight: 800; color: var(--accent-blue);">104x</div>
        <div style="color: var(--text-secondary); font-size: 0.85rem; margin-top: 0.3rem;">Improvement factor</div>
      </div>
    </div>

    <!-- ===================== SECTION 1: THE CREDIT ASSIGNMENT PROBLEM ===================== -->
    <section style="margin-bottom: 3rem;">
      <h2 style="font-size: 1.9rem; font-weight: 700; color: var(--text-primary); margin-bottom: 1.2rem; padding-bottom: 0.5rem; border-bottom: 1px solid var(--border);">
        1. The Credit Assignment Problem in Tetris
      </h2>
      <div class="prose">
        <p>
          In supervised learning, every data point has a label. In RL, reward is the only learning
          signal -- and in Tetris, it arrives rarely and with a massive <strong>temporal gap</strong>
          between action and consequence.
        </p>
        <p>
          Consider this chain of events: the agent places an S-piece awkwardly in row 15, creating
          a hole. Over the next 30 moves, every subsequent piece must stack higher to accommodate
          this hole. Eventually, 40 moves later, the board reaches the top and the game ends.
        </p>
        <p>
          With sparse rewards (only line clears), the agent receives signal for the game-over
          event, but gets zero feedback for the 40 intermediate moves that caused it. With
          gamma=0.99, the game-over penalty is discounted by 0.99^40 ~= 0.67 -- significantly weakened.
          More critically, the connection between "placed S-piece awkwardly 40 steps ago" and
          "game over now" is essentially invisible to a Q-learning agent without very extensive
          experience.
        </p>
        <p>
          This is the <strong>credit assignment problem</strong>: how do we assign blame or credit
          to past actions when consequences are delayed? Reward shaping is one solution -- encode
          the relevant domain knowledge directly into the reward function.
        </p>
      </div>

      <div class="callout callout-warning">
        <strong>Theoretical caveat:</strong> Reward shaping can change the optimal policy if done
        incorrectly. Only <em>potential-based shaping</em> (Ng et al., 1999) guarantees policy
        invariance: F(s,a,s') = gamma.?(s') - ?(s). Our shape functions approximate this but do not
        strictly satisfy it -- we're making the engineering trade-off of faster learning over
        theoretical guarantee.
      </div>
    </section>

    <!-- ===================== SECTION 2: THE REWARD FUNCTION ===================== -->
    <section style="margin-bottom: 3rem;">
      <h2 style="font-size: 1.9rem; font-weight: 700; color: var(--text-primary); margin-bottom: 1.2rem; padding-bottom: 0.5rem; border-bottom: 1px solid var(--border);">
        2. The Shaped Reward Function
      </h2>
      <div class="prose">
        <p>
          The final reward function (Experiment 2 / baseline configuration) is computed at each
          placement step:
        </p>
      </div>

      <div class="formula-box" style="margin: 1.5rem 0;">
        <div style="font-size: 1rem; margin-bottom: 1rem; text-align: center;">R(afterstate)</div>
        R = line_reward(n) - 0.1 . ?t - 4.0 . ?holes - 0.1 . ?bump - 0.1 . ?height - 100 . game_over
        <div style="margin-top: 1rem; display: grid; grid-template-columns: auto 1fr; gap: 0.4rem 1rem; font-size: 0.88rem;">
          <span style="color: var(--accent-green); font-weight: 700;">line_reward(n)</span>
          <span>Tiered reward for n lines cleared: [0, 10, 30, 60, 100] for n  in  &#123;0,1,2,3,4&#125;</span>
          <span style="color: var(--accent-orange); font-weight: 700;">-0.1 . ?t</span>
          <span>Time penalty: small constant per step to discourage stalling</span>
          <span style="color: var(--accent-orange); font-weight: 700;">-4.0 . ?holes</span>
          <span>Hole penalty: strong punishment for each new hole created</span>
          <span style="color: var(--accent-orange); font-weight: 700;">-0.1 . ?bump</span>
          <span>Bumpiness penalty: discourages jagged column profiles</span>
          <span style="color: var(--accent-orange); font-weight: 700;">-0.1 . ?height</span>
          <span>Height penalty: discourages unnecessarily tall stacks</span>
          <span style="color: var(--accent-orange); font-weight: 700;">-100 . game_over</span>
          <span>Terminal penalty: large negative reward for dying</span>
        </div>
        <div style="margin-top: 0.8rem; font-size: 0.85rem; color: var(--text-secondary);">
          ? denotes change from previous step to current step (afterstate delta).
        </div>
      </div>

      <h3 style="font-size: 1.3rem; color: var(--text-primary); margin: 1.8rem 0 0.8rem;">Line Clear Reward Tiers</h3>
      <div class="prose">
        <p>
          The tiered line-clear reward is superlinear: clearing 4 lines (Tetris) gives 100 points,
          not 4x10=40. This <strong>incentivises Tetris clears</strong> -- the most efficient way
          to clear the board. The quadratic scaling mimics Tetris scoring systems and encourages
          the agent to set up for multi-line clears rather than clearing one line at a time.
        </p>
      </div>
      <div style="overflow-x: auto; margin: 1rem 0;">
        <table style="width: 100%; border-collapse: collapse; font-size: 0.9rem; max-width: 500px;">
          <thead>
            <tr style="background: var(--bg-secondary);">
              <th style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Lines Cleared</th>
              <th style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Reward</th>
              <th style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Per-line Rate</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">0 (no clear)</td>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">0</td>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">--</td>
            </tr>
            <tr style="background: var(--bg-secondary);">
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">1 (Single)</td>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">10</td>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">10.0</td>
            </tr>
            <tr>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">2 (Double)</td>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">30</td>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">15.0</td>
            </tr>
            <tr style="background: var(--bg-secondary);">
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">3 (Triple)</td>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">60</td>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">20.0</td>
            </tr>
            <tr>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border);">4 (Tetris)</td>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border); color: var(--accent-green); font-weight: 700;">100</td>
              <td style="padding: 0.6rem 1rem; border: 1px solid var(--border); color: var(--accent-green);">25.0</td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>

    <!-- ===================== SECTION 3: EXPERIMENTS ===================== -->
    <section style="margin-bottom: 3rem;">
      <h2 style="font-size: 1.9rem; font-weight: 700; color: var(--text-primary); margin-bottom: 1.2rem; padding-bottom: 0.5rem; border-bottom: 1px solid var(--border);">
        3. Experimental Results
      </h2>

      <!-- Results table -->
      <div style="overflow-x: auto; margin-bottom: 2rem;">
        <table style="width: 100%; border-collapse: collapse; font-size: 0.88rem;">
          <thead>
            <tr style="background: var(--bg-secondary);">
              <th style="padding: 0.75rem 1rem; border: 1px solid var(--border); text-align: left;">Experiment</th>
              <th style="padding: 0.75rem 1rem; border: 1px solid var(--border); text-align: left;">Reward Components</th>
              <th style="padding: 0.75rem 1rem; border: 1px solid var(--border); text-align: left;">Max Lines</th>
              <th style="padding: 0.75rem 1rem; border: 1px solid var(--border); text-align: left;">Avg Lines @ 100K ep</th>
              <th style="padding: 0.75rem 1rem; border: 1px solid var(--border); text-align: left;">Key Finding</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); font-weight: 600;">E1: Pure sparse</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Only game outcome (win/lose)</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); color: var(--accent-orange);">47</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">12</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Agent never learns to play</td>
            </tr>
            <tr style="background: var(--bg-secondary);">
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); font-weight: 600;">E2: Intrinsic only</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Line clears + game over</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); color: var(--accent-orange);">216</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">83</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Learns to survive but stacks messily</td>
            </tr>
            <tr>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); font-weight: 600;">E3: Holes only</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Lines + holes penalty + game over</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); color: var(--accent-blue);">4,210</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">1,340</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Single biggest lever: holes penalty</td>
            </tr>
            <tr style="background: var(--bg-secondary);">
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); font-weight: 600;">E4: Full baseline</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">All components (Section 2)</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); color: var(--accent-green); font-weight: 700;">22,645</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); font-weight: 700;">8,340</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); color: var(--accent-green);">All penalties synergistically combine</td>
            </tr>
            <tr>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); font-weight: 600;">E5: Hole coeff x 2</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">As E4 but holes penalty = -8.0</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); color: var(--accent-orange);">11,203</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">4,120</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Over-penalises; agent plays overly flat boards</td>
            </tr>
            <tr style="background: var(--bg-secondary);">
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); font-weight: 600;">E6: Exponential lines</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">As E4 but reward = 10^n</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); color: var(--accent-orange);">6,780</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">2,890</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Too greedy for Tetris clears; misses singles</td>
            </tr>
            <tr>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); font-weight: 600;">E7: No time penalty</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">As E4 without time penalty</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border); color: var(--accent-blue);">19,440</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">7,100</td>
              <td style="padding: 0.7rem 1rem; border: 1px solid var(--border);">Marginally worse; time penalty small but helpful</td>
            </tr>
          </tbody>
        </table>
      </div>
    </section>

    <!-- ===================== SECTION 4: EACH PENALTY EXPLAINED ===================== -->
    <section style="margin-bottom: 3rem;">
      <h2 style="font-size: 1.9rem; font-weight: 700; color: var(--text-primary); margin-bottom: 1.2rem; padding-bottom: 0.5rem; border-bottom: 1px solid var(--border);">
        4. The Role of Each Penalty -- Scientific Analysis
      </h2>

      <!-- Holes penalty -->
      <div style="margin-bottom: 2rem;">
        <h3 style="font-size: 1.3rem; color: var(--accent-orange); margin-bottom: 0.8rem;">
          Hole Penalty (-4.0 x ?holes) -- The Critical Signal
        </h3>
        <div class="prose">
          <p>
            The hole penalty is by far the most important component (Experiment 3 shows holes alone
            gives 4,210 lines vs 216 without it). Here is why it works scientifically:
          </p>
          <p>
            A hole is an empty cell with at least one filled cell above it. In Tetris, holes
            cannot be directly filled -- every cell above a hole must be cleared first. This means
            a hole at row 15 in a 16-high stack requires clearing rows 0-14 (15 complete rows)
            before that hole can ever contribute to a line clear.
          </p>
          <p>
            Without the hole penalty, the agent has no immediate signal to avoid holes. The
            consequence of creating a hole at step t doesn't materialise as a negative reward
            until the game ends, potentially 40+ steps later. With gamma=0.99, this means the
            penalty is discounted by ~0.67 at minimum -- and the connection is invisible to the
            TD-learning algorithm.
          </p>
          <p>
            The hole penalty makes holes immediately costly: every new hole created at step t
            generates an immediate penalty of -4.0 in the reward. This dramatically reduces the
            credit assignment gap from 40+ steps to 0 steps.
          </p>
        </div>
        <div class="formula-box">
          Without penalty: ?Q(hole-creating action) = -100 x 0.99^{'{'}40{'}'} / N_steps ~= -0.017 per step<br />
          With penalty: ?Q(hole-creating action) = -4.0 immediately (plus future consequences)
        </div>
      </div>

      <!-- Bumpiness penalty -->
      <div style="margin-bottom: 2rem;">
        <h3 style="font-size: 1.3rem; color: var(--accent-blue); margin-bottom: 0.8rem;">
          Bumpiness Penalty (-0.1 x ?bumpiness) -- Surface Regularity
        </h3>
        <div class="prose">
          <p>
            Bumpiness measures how uneven the column height profile is. A jagged surface increases
            the probability of future holes: when a piece is placed on a jagged surface, the
            overhangs of tall adjacent columns often create holes beneath the placed piece.
          </p>
          <p>
            The bumpiness penalty is weaker than the hole penalty (0.1 vs 4.0) because it's a
            <em>leading indicator</em> of future holes rather than a direct consequence. The
            coefficient was tuned empirically: too strong and the agent stacks inefficiently flat;
            too weak and it provides no useful signal.
          </p>
        </div>
      </div>

      <!-- Height penalty -->
      <div style="margin-bottom: 2rem;">
        <h3 style="font-size: 1.3rem; color: var(--accent-purple); margin-bottom: 0.8rem;">
          Height Penalty (-0.1 x ?height) -- Danger Proximity
        </h3>
        <div class="prose">
          <p>
            The height penalty penalises increases in the aggregate stack height. This serves a
            different purpose than the hole penalty: it encourages the agent to clear lines
            proactively rather than letting the stack grow until it's too late.
          </p>
          <p>
            Without the height penalty, the agent might tolerate a growing stack as long as no
            new holes are being created. The height penalty creates an urgency to keep the board
            clear, aligning with optimal Tetris strategy.
          </p>
        </div>
      </div>

      <!-- Time penalty -->
      <div style="margin-bottom: 2rem;">
        <h3 style="font-size: 1.3rem; color: var(--accent-cyan); margin-bottom: 0.8rem;">
          Time Penalty (-0.1 per step) -- Survival Incentive
        </h3>
        <div class="prose">
          <p>
            The time penalty seems counterproductive -- why penalise the agent for surviving longer?
            The key is that without it, the agent is indifferent between placing pieces quickly
            (and potentially clearing lines) versus... well, there's no "delay" in Tetris, so
            this is mainly a small normalisation signal.
          </p>
          <p>
            Its primary function is to make each step have a non-zero cost, which slightly
            accelerates learning by providing signal even on steps with no other reward. It also
            prevents the agent from being completely indifferent to the number of moves taken.
            Experiment 7 (removing time penalty) shows only a marginal degradation, confirming
            it's the weakest component.
          </p>
        </div>
      </div>

      <!-- Game over penalty -->
      <div style="margin-bottom: 1rem;">
        <h3 style="font-size: 1.3rem; color: var(--accent-orange); margin-bottom: 0.8rem;">
          Game Over Penalty (-100) -- The Stakes
        </h3>
        <div class="prose">
          <p>
            The large terminal penalty ensures the agent understands that dying is very bad.
            Its magnitude (-100) is chosen to be larger than the maximum possible reward from
            a single Tetris clear (100 points), ensuring death is always the worst outcome.
          </p>
          <p>
            Without it, the agent might be willing to sacrifice the game for a short-term high
            score. With it, self-preservation is always strictly more valuable than any single
            placement benefit.
          </p>
        </div>
      </div>
    </section>

    <!-- ===================== SECTION 5: OPTIMIZATION LANDSCAPE ===================== -->
    <section style="margin-bottom: 3rem;">
      <h2 style="font-size: 1.9rem; font-weight: 700; color: var(--text-primary); margin-bottom: 1.2rem; padding-bottom: 0.5rem; border-bottom: 1px solid var(--border);">
        5. How Reward Shaping Changes the Optimization Landscape
      </h2>
      <div class="prose">
        <p>
          From a theoretical perspective, reward shaping changes the <em>effective discount factor</em>
          as seen by the learning algorithm. The key insight is in the gradient signal density:
        </p>
      </div>

      <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 1.5rem; margin: 1.5rem 0;">
        <div class="stat-card" style="border-top: 3px solid var(--accent-orange);">
          <h3 style="color: var(--accent-orange); margin-bottom: 0.8rem;">Without Shaping</h3>
          <p style="color: var(--text-secondary); font-size: 0.9rem; margin-bottom: 0.8rem;">
            Reward arrives at most once per episode (game over). For a typical episode of 50
            placements, only 1 in 50 steps has a non-zero reward gradient. The gradient signal
            is extremely sparse.
          </p>
          <div class="formula-box" style="font-size: 0.85rem;">
            Effective signal density: ~2% of steps
          </div>
        </div>
        <div class="stat-card" style="border-top: 3px solid var(--accent-green);">
          <h3 style="color: var(--accent-green); margin-bottom: 0.8rem;">With Shaping</h3>
          <p style="color: var(--text-secondary); font-size: 0.9rem; margin-bottom: 0.8rem;">
            Every placement generates a non-zero reward (hole delta, height delta, bumpiness delta
            are almost always non-zero). The agent receives meaningful gradient signal at every
            single step.
          </p>
          <div class="formula-box" style="font-size: 0.85rem;">
            Effective signal density: ~100% of steps
          </div>
        </div>
      </div>

      <div class="prose">
        <p>
          This 50x increase in gradient density explains a significant portion of the 100x
          performance improvement. More gradients = faster convergence = better policy at any
          given number of episodes.
        </p>
        <p>
          Additionally, the shaped reward function is <strong>smoother</strong> in the Q-value
          landscape. Similar board positions get similar rewards, which means the function the
          neural network must approximate is more learnable. The unshaped reward landscape has
          many flat regions (no signal) punctuated by sharp spikes (rare line clears).
        </p>
        <p>
          Finally, shaped rewards provide <strong>sample efficiency</strong>: they encode human
          domain knowledge (holes are bad, flat surfaces are good) that would otherwise require
          millions of experiences to discover. This is the fundamental engineering trade-off of
          reward shaping -- speed vs generality.
        </p>
      </div>

      <div class="callout callout-info">
        <strong>An analogy:</strong> Training with sparse rewards is like teaching someone to cook
        by only telling them "good meal" or "bad meal" after they eat. Shaped rewards are like
        telling them "the onions are browning nicely, the salt balance is off, and the heat is
        too high" throughout the cooking process. The latter is far more informative.
      </div>
    </section>

    <!-- Navigation -->
    <div style="display: flex; gap: 1rem; flex-wrap: wrap; margin-top: 2.5rem; padding-top: 1.5rem; border-top: 1px solid var(--border);">
      <a href={`${base}tetris/architecture/`}
         style="padding: 0.7rem 1.4rem; background: var(--bg-secondary); color: var(--text-primary); border: 1px solid var(--border); border-radius: 6px; text-decoration: none; font-weight: 600;">
        &lt;- Architecture
      </a>
      <a href={`${base}tetris/training/`}
         style="padding: 0.7rem 1.4rem; background: var(--accent-green); color: white; border-radius: 6px; text-decoration: none; font-weight: 600;">
        Training Pipeline ->
      </a>
      <a href={`${base}tetris/`}
         style="padding: 0.7rem 1.4rem; background: var(--bg-secondary); color: var(--text-primary); border: 1px solid var(--border); border-radius: 6px; text-decoration: none; font-weight: 600;">
        Project Overview
      </a>
    </div>

  </div>
</Layout>
